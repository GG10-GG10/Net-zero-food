# -*- coding: utf-8 -*-
"""
S3.2 Feed demand builder
-----------------------
Derives livestock feed requirements (grass + crop) directly from
country-level livestock stocks and parameter tables stored under
input/Land/Feed_pasture/.
"""
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
import os
import logging
import numpy as np
import pandas as pd

from S1_0_schema import Universe
from S2_0_load_data import DataPaths, EmisItemMappings

# é…ç½®logger
logger = logging.getLogger(__name__)


@dataclass
class FeedDemandOutputs:
    crop_feed_demand: pd.DataFrame
    grass_requirement: pd.DataFrame
    species_dm_detail: pd.DataFrame


def build_feed_demand_from_stock(*,
                                 stock_df: pd.DataFrame,
                                 universe: Universe,
                                 maps: EmisItemMappings,
                                 paths: DataPaths,
                                 years: List[int],
                                 conversion_multiplier: Optional[Dict[Tuple[str, str, int], float]] = None) -> FeedDemandOutputs:
    """
    Convert stock_head (by commodity/country/year) into:
      1) species-level DM requirements from Feed_need_per_head...xlsx
      2) grass vs crop DM split via Grass_feed_ratio...
      3) crop-specific feed demand by commodity (converted to grain using dm_conversion_coefficients)
      4) grass DM requirement + implied pasture area using Pasture_DM_yield_by_country.xlsx
    """
    # âœ… æ‰€æœ‰DataFrameéƒ½åŒ…å«M49_Country_Codeåˆ—
    empty = FeedDemandOutputs(
        crop_feed_demand=pd.DataFrame(columns=['M49_Country_Code','country','iso3','year','commodity','feed_t']),
        grass_requirement=pd.DataFrame(columns=['M49_Country_Code','country','iso3','year','grass_tdm','grass_area_need_ha']),
        species_dm_detail=pd.DataFrame(columns=[
            'country','iso3','m49_code','year','commodity','species',
            'stock_head','kg_dm_per_head','dm_total_kg','grass_dm_kg','crop_dm_kg'
        ])
    )
    if stock_df is None or stock_df.empty:
        return empty
    conv_mult: Dict[Tuple[str, str, int], float] = {}
    for key, val in (conversion_multiplier or {}).items():
        try:
            country, commodity, year = key
            conv_mult[(str(country), str(commodity), int(year))] = float(val)
        except Exception:
            continue

    if not (paths.feed_need_xlsx and os.path.exists(paths.feed_need_xlsx)):
        logger.error(f"[S3_2 ERROR] Feed_needæ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„ä¸ºNone: {paths.feed_need_xlsx}")
        return empty
    if not (paths.grass_ratio_xlsx and os.path.exists(paths.grass_ratio_xlsx)):
        logger.error(f"[S3_2 ERROR] âŒâŒâŒ Grass_ratioæ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„ä¸ºNone: {paths.grass_ratio_xlsx}")
        logger.error(f"[S3_2 ERROR] è¿™æ˜¯å¯¼è‡´è‰åœ°éœ€æ±‚ç¼ºå¤±çš„æ ¹æœ¬åŸå› ï¼")
        return empty
    if not (paths.pasture_dm_yield_xlsx and os.path.exists(paths.pasture_dm_yield_xlsx)):
        logger.error(f"[S3_2 ERROR] Pasture_yieldæ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„ä¸ºNone: {paths.pasture_dm_yield_xlsx}")
        return empty

    years = sorted(set(int(y) for y in years))
    logger.info(f"[S3_2 DEBUG] è¯·æ±‚çš„years: {years}")
    
    comm_to_species = {comm: feed_item for feed_item, comm in (maps.feed_item_to_comm or {}).items()}
    logger.info(f"[S3_2 DEBUG] comm_to_speciesæ˜ å°„: {len(comm_to_species)} ä¸ªcommodity")
    if len(comm_to_species) > 0:
        logger.info(f"[S3_2 DEBUG] æ˜ å°„æ ·ä¾‹: {list(comm_to_species.items())[:5]}")
    
    # âœ… æ³¨æ„ï¼šcomm_to_speciesçš„keyæ˜¯Item_Emisï¼Œvalueæ˜¯Item_Feed_Mapï¼ˆspeciesï¼‰
    # ä¾‹å¦‚ï¼š{"Cattle, dairy": "dairy_cattle", "Cattle, non-dairy": "beef_cattle"}
    # ä½†ä¼ å…¥çš„stock_df.commodityåº”è¯¥å·²ç»æ˜¯Item_Feed_Mapæ ¼å¼ï¼ˆspeciesåç§°ï¼‰
    # æ‰€ä»¥è¿™é‡Œçš„æ˜ å°„æ˜¯åå‘çš„ï¼Œéœ€è¦è°ƒæ•´ï¼
    
    if not comm_to_species:
        logger.error(f"[S3_2 ERROR] âŒ comm_to_speciesæ˜ å°„ä¸ºç©ºï¼")
        return empty

    country_to_m49 = {}
    m49_to_country = {}
    for country, code in (universe.m49_by_country or {}).items():
        parsed = _parse_m49(code)
        if parsed is None:
            continue
        country_to_m49[country] = parsed
        m49_to_country[parsed] = country

    if not country_to_m49:
        return empty

    stock = stock_df.copy()
    logger.info(f"[S3_2 DEBUG] è¾“å…¥å­˜æ æ•°æ®: {len(stock)} è¡Œ")
    if 'year' in stock.columns:
        stock_years = sorted(stock['year'].unique())
        logger.info(f"[S3_2 DEBUG] å­˜æ å¹´ä»½: {stock_years}")
    
    # è¯Šæ–­ï¼šæ£€æŸ¥ä¼ å…¥çš„commodityå€¼
    if 'commodity' in stock.columns:
        unique_commodities = stock['commodity'].unique()
        logger.info(f"[S3_2 DEBUG] ä¼ å…¥çš„commodityå€¼æ ·ä¾‹: {list(unique_commodities)[:10]}")
    
    stock['m49_code'] = stock['country'].map(country_to_m49)
    
    # âœ… æ˜ å°„commodityï¼ˆItem_Emisæ ¼å¼ï¼Œå¦‚'Cattle, non-dairy'ï¼‰åˆ°speciesï¼ˆItem_Feed_Mapæ ¼å¼ï¼Œå¦‚'beef_cattle'ï¼‰
    # comm_to_speciesåº”è¯¥æ˜¯: {Item_Emis: Item_Feed_Map}
    # ä½†ç”±äºfeed_item_to_commåè½¬ï¼Œå®é™…comm_to_specieså¯èƒ½æ˜¯åå‘çš„ï¼Œéœ€è¦ä¿®æ­£
    
    # ğŸ” è¯Šæ–­ï¼šæ‰“å°comm_to_specieså†…å®¹ï¼Œæ£€æŸ¥dairyå“ç§
    logger.info(f"[S3_2 DEBUG] comm_to_speciesæ˜ å°„æ•°é‡: {len(comm_to_species)}")
    dairy_check = {k: v for k, v in comm_to_species.items() if 'dairy' in str(k).lower() and 'non-dairy' not in str(k).lower()}
    logger.info(f"[S3_2 DEBUG] comm_to_speciesä¸­dairyå“ç§: {dairy_check}")
    
    # å…ˆå°è¯•ç›´æ¥æ˜ å°„
    stock['species'] = stock['commodity'].map(comm_to_species)
    
    # å¦‚æœæ˜ å°„å¤±è´¥ï¼ˆå¤§éƒ¨åˆ†æ˜¯NaNï¼‰ï¼Œè¯´æ˜comm_to_speciesæ˜¯åå‘çš„ï¼Œéœ€è¦åè½¬å›æ¥
    unmapped_count = stock['species'].isna().sum()
    if unmapped_count > len(stock) * 0.5:  # å¦‚æœè¶…è¿‡50%æ²¡åŒ¹é…ä¸Š
        logger.warning(f"[S3_2 WARNING] comm_to_speciesæ˜ å°„å¤±è´¥ç‡é«˜({unmapped_count}/{len(stock)})ï¼Œå°è¯•åè½¬æ˜ å°„...")
        # åè½¬æ˜ å°„ï¼š{commodity: feed_item} -> {feed_item: commodity}
        species_to_comm = {v: k for k, v in comm_to_species.items()}
        # æ„å»ºcommodityåˆ°feed_itemçš„æ­£ç¡®æ˜ å°„
        correct_mapping = {}
        for commodity in stock['commodity'].unique():
            if pd.isna(commodity):
                continue
            # å°è¯•åœ¨species_to_commçš„å€¼ä¸­æŸ¥æ‰¾
            for feed_item, comm in species_to_comm.items():
                if comm == commodity:
                    correct_mapping[commodity] = feed_item
                    break
        logger.info(f"[S3_2 DEBUG] æ„å»ºçš„æ­£ç¡®æ˜ å°„ç¤ºä¾‹: {list(correct_mapping.items())[:5]}")
        stock['species'] = stock['commodity'].map(correct_mapping)
    
    # âœ… å…³é”®ä¿®å¤ï¼šå¯¹äºä»æœªæ˜ å°„çš„dairyå“ç§ï¼Œç›´æ¥ä»dict_v3è¡¥å……
    still_unmapped = stock['species'].isna()
    if still_unmapped.any():
        unmapped_commodities = stock[still_unmapped]['commodity'].unique()
        dairy_unmapped = [c for c in unmapped_commodities if 'dairy' in str(c).lower() and 'non-dairy' not in str(c).lower()]
        
        if dairy_unmapped:
            logger.warning(f"[S3_2 DAIRY_FIX] æ£€æµ‹åˆ°{len(dairy_unmapped)}ä¸ªdairyå“ç§æœªæ˜ å°„ï¼Œä»dict_v3è¡¥å……: {dairy_unmapped}")
            
            # ç›´æ¥ä»dict_v3åŠ è½½dairyæ˜ å°„
            try:
                dict_v3_path = paths.dict_v3_path if hasattr(paths, 'dict_v3_path') else None
                if dict_v3_path and os.path.exists(dict_v3_path):
                    emis_df = pd.read_excel(dict_v3_path, sheet_name='Emis_item')
                    dairy_mapping = {}
                    for _, row in emis_df.iterrows():
                        item_emis = row.get('Item_Emis')
                        item_feed = row.get('Item_Feed_Map')
                        if pd.notna(item_emis) and pd.notna(item_feed):
                            if 'dairy' in str(item_emis).lower() and 'non-dairy' not in str(item_emis).lower():
                                dairy_mapping[item_emis] = item_feed
                    
                    logger.info(f"[S3_2 DAIRY_FIX] ä»dict_v3åŠ è½½dairyæ˜ å°„: {dairy_mapping}")
                    
                    # åº”ç”¨dairyæ˜ å°„åˆ°æœªæ˜ å°„çš„è¡Œ
                    for commodity in dairy_unmapped:
                        if commodity in dairy_mapping:
                            mask = (stock['commodity'] == commodity) & stock['species'].isna()
                            stock.loc[mask, 'species'] = dairy_mapping[commodity]
                            logger.info(f"[S3_2 DAIRY_FIX] ä¿®å¤: {commodity} â†’ {dairy_mapping[commodity]} ({mask.sum()} è¡Œ)")
            except Exception as e:
                logger.error(f"[S3_2 DAIRY_FIX] ä»dict_v3è¡¥å……dairyæ˜ å°„å¤±è´¥: {e}")
    
    # æœ€åæ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªæ˜ å°„çš„
    unmapped = stock['species'].isna()
    if unmapped.any():
        logger.warning(f"[S3_2 WARNING] {unmapped.sum()} è¡Œcommodityæ— æ³•æ˜ å°„åˆ°speciesï¼Œå°†è¢«è¿‡æ»¤")
    
    stock['iso3'] = stock['iso3'].fillna(stock['country'].map(universe.iso3_by_country))
    
    logger.info(f"[S3_2 DEBUG] æ˜ å°„å: m49_codeç¼ºå¤±={stock['m49_code'].isna().sum()}, speciesç¼ºå¤±={stock['species'].isna().sum()}")
    
    # ğŸ” è¯Šæ–­ï¼šä»¥ç¾å›½ä¸ºä¾‹è¿½è¸ªspeciesæ˜ å°„
    us_stock = stock[stock['country'] == 'United States of America']
    if not us_stock.empty:
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ” [ç¾å›½æ•°æ®æµ] Step 4: speciesæ˜ å°„å®Œæˆ")
        logger.info("=" * 80)
        logger.info(f"ç¾å›½å­˜æ æ•°æ®: {len(us_stock)} è¡Œ")
        us_sample = us_stock[['commodity', 'species', 'stock_head', 'year']].head(10)
        for _, row in us_sample.iterrows():
            logger.info(f"  commodity={row['commodity']:15s} | species={row['species']:15s} | {row['stock_head']:>12,.0f} head ({row['year']}å¹´)")
    stock = stock.dropna(subset=['m49_code', 'species'])
    logger.info(f"[S3_2 DEBUG] dropnaå: {len(stock)} è¡Œ")
    
    # ğŸ” å¢å¼ºè¯Šæ–­ï¼šåœ¨è¿‡æ»¤å‰æ£€æŸ¥stock_headåˆ—
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ” [S3_2è¯Šæ–­] stock_headè¿‡æ»¤å‰æ£€æŸ¥")
    logger.info("=" * 80)
    logger.info(f"stock_headåˆ—ç±»å‹: {stock['stock_head'].dtype}")
    logger.info(f"stock_headéç©ºè¡Œæ•°: {stock['stock_head'].notna().sum()}/{len(stock)}")
    logger.info(f"stock_head>0è¡Œæ•°ï¼ˆè¿‡æ»¤å‰ï¼‰: {(stock['stock_head'] > 0).sum()}/{len(stock)}")
    logger.info(f"stock_headæ€»å’Œ: {stock['stock_head'].sum():,.0f}")
    if len(stock) > 0:
        logger.info(f"stock_headèŒƒå›´: {stock['stock_head'].min():.2e} ~ {stock['stock_head'].max():.2e}")
        logger.info(f"stock_headæ ·ä¾‹ï¼ˆå‰5è¡Œï¼‰: {stock['stock_head'].head().tolist()}")
    
    stock['stock_head'] = pd.to_numeric(stock['stock_head'], errors='coerce').fillna(0.0)
    
    # ğŸ” è¯Šæ–­ï¼šnumericè½¬æ¢åçš„çŠ¶æ€
    logger.info(f"numericè½¬æ¢åstock_head>0è¡Œæ•°: {(stock['stock_head'] > 0).sum()}/{len(stock)}")
    logger.info(f"numericè½¬æ¢åstock_headæ€»å’Œ: {stock['stock_head'].sum():,.0f}")
    
    stock = stock[stock['stock_head'] > 0]
    logger.info(f"[S3_2 DEBUG] è¿‡æ»¤stock_head>0å: {len(stock)} è¡Œ")
    logger.info("=" * 80 + "\n")
    
    if stock.empty:
        logger.error(f"[S3_2 ERROR] âŒ å­˜æ æ•°æ®ä¸ºç©ºï¼Œæå‰è¿”å›ï¼")
        return empty

    dm_per_head = _load_total_dm_per_head(paths.feed_need_xlsx, years)
    crop_share = _load_crop_share(paths.feed_need_xlsx, years)
    dm_conversion = _load_dm_conversion(paths.feed_need_xlsx, years)
    grass_ratio = _load_grass_ratio(paths.grass_ratio_xlsx)
    pasture_yield = _load_pasture_yield(paths.pasture_dm_yield_xlsx)
    
    # âœ… è¯Šæ–­ï¼šç¡®è®¤å‚æ•°æ•°æ®çš„å¹´ä»½èŒƒå›´
    if not dm_per_head.empty and 'year' in dm_per_head.columns:
        param_years = sorted(dm_per_head['year'].unique())
        logger.info(f"[S3_2 DEBUG] dm_per_headå¹´ä»½èŒƒå›´: {param_years[:3]}...{param_years[-3:]}, å…±{len(param_years)}å¹´")
        if 2080 in param_years:
            logger.info(f"[S3_2 DEBUG] âœ… dm_per_headåŒ…å«2080å¹´æ•°æ®ï¼ˆå‰å‘å¡«å……æˆåŠŸï¼‰")
        else:
            logger.info(f"[S3_2 DEBUG] âŒ dm_per_headç¼ºå°‘2080å¹´æ•°æ®ï¼")

    if dm_per_head.empty or crop_share.empty or dm_conversion.empty:
        logger.error(f"[S3_2 ERROR] âŒ å‚æ•°æ•°æ®ä¸ºç©º: dm_per_head={dm_per_head.empty}, crop_share={crop_share.empty}, dm_conversion={dm_conversion.empty}")
        return empty

    logger.info(f"[S3_2 DEBUG] mergeå‰stock: {len(stock)} è¡Œ, dm_per_head: {len(dm_per_head)} è¡Œ")
    # è¯Šæ–­ï¼šæ£€æŸ¥specieså€¼åŒ¹é…
    stock_species = set(stock['species'].unique())
    dm_species = set(dm_per_head['species'].unique())
    logger.info(f"[S3_2 DEBUG] stockä¸­çš„species ({len(stock_species)}ä¸ª): {sorted(list(stock_species))[:10]}")
    logger.info(f"[S3_2 DEBUG] dm_per_headä¸­çš„species ({len(dm_species)}ä¸ª): {sorted(list(dm_species))[:10]}")
    overlap = stock_species & dm_species
    logger.info(f"[S3_2 DEBUG] äº¤é›†species: {len(overlap)} ä¸ª")
    if len(overlap) == 0:
        logger.error(f"[S3_2 ERROR] âŒ stockå’Œdm_per_headçš„specieså®Œå…¨ä¸åŒ¹é…ï¼")
        logger.error(f"[S3_2 ERROR] stockç¤ºä¾‹: {list(stock_species)[:5]}")
        logger.error(f"[S3_2 ERROR] dm_per_headç¤ºä¾‹: {list(dm_species)[:5]}")
    
    stock = stock.merge(
        dm_per_head,
        how='left',
        left_on=['species','m49_code','year'],
        right_on=['species','m49_code','year']
    )
    logger.info(f"[S3_2 DEBUG] mergeå: {len(stock)} è¡Œ")
    
    stock['kg_dm_per_head'] = pd.to_numeric(stock['kg_dm_per_head'], errors='coerce')
    kg_dm_na = stock['kg_dm_per_head'].isna().sum()
    logger.info(f"[S3_2 DEBUG] kg_dm_per_headç¼ºå¤±: {kg_dm_na}/{len(stock)} è¡Œ")
    
    # ğŸ” è¯Šæ–­ï¼šä»¥ç¾å›½ä¸ºä¾‹è¿½è¸ªDM per headåŒ¹é…
    us_stock = stock[stock['country'] == 'United States of America']
    if not us_stock.empty:
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ” [ç¾å›½æ•°æ®æµ] Step 5: DM per headå‚æ•°åŒ¹é…")
        logger.info("=" * 80)
        logger.info(f"ç¾å›½å­˜æ æ•°æ®: {len(us_stock)} è¡Œ")
        us_sample = us_stock[['species', 'stock_head', 'kg_dm_per_head', 'year']].head(10)
        for _, row in us_sample.iterrows():
            dm_status = f"{row['kg_dm_per_head']:.1f}" if pd.notna(row['kg_dm_per_head']) else "âŒ NaN"
            logger.info(f"  {row['species']:15s} | {row['stock_head']:>12,.0f} head | DM={dm_status:>8s} kg/head ({row['year']}å¹´)")
    
    stock = stock.dropna(subset=['kg_dm_per_head'])
    logger.info(f"[S3_2 DEBUG] dropna(kg_dm_per_head)å: {len(stock)} è¡Œ")
    
    if stock.empty:
        logger.error(f"[S3_2 ERROR] âŒ merge dm_per_headåæ•°æ®ä¸ºç©ºï¼Œæå‰è¿”å›ï¼")
        logger.error(f"[S3_2 ERROR] å¯èƒ½åŸå› ï¼šå­˜æ çš„species/m49_code/yearç»„åˆåœ¨dm_per_headä¸­æ‰¾ä¸åˆ°åŒ¹é…")
        return empty
    stock['dm_total_kg'] = stock['stock_head'] * stock['kg_dm_per_head']

    stock = stock.merge(
        grass_ratio,
        how='left',
        on=['species','m49_code']
    )
    stock['grass_ratio'] = stock['grass_ratio'].clip(lower=0.0, upper=1.0).fillna(0.0)
    stock['crop_ratio'] = stock['crop_ratio'].clip(lower=0.0, upper=1.0)
    stock['crop_ratio'] = stock['crop_ratio'].fillna(1.0 - stock['grass_ratio'])
    stock['crop_ratio'] = stock['crop_ratio'].clip(lower=0.0, upper=1.0)
    stock['grass_dm_kg'] = stock['dm_total_kg'] * stock['grass_ratio']
    stock['crop_dm_kg'] = stock['dm_total_kg'] * stock['crop_ratio']

    crop_dm_rows = stock[['country','iso3','m49_code','year','species','dm_total_kg','crop_ratio']].merge(
        crop_share,
        how='left',
        on=['species','m49_code','year']
    )
    crop_dm_rows['share'] = crop_dm_rows['share'].clip(lower=0.0)
    crop_dm_rows['share'] = crop_dm_rows['share'].fillna(0.0)
    crop_dm_rows['crop_dm_kg'] = crop_dm_rows['dm_total_kg'] * crop_dm_rows['crop_ratio'] * crop_dm_rows['share']
    crop_dm_rows = crop_dm_rows[crop_dm_rows['crop_dm_kg'] > 0]
    if crop_dm_rows.empty:
        crop_feed_demand = pd.DataFrame(columns=['M49_Country_Code','country','iso3','year','commodity','feed_t'])
    else:
        crop_dm_rows = crop_dm_rows.merge(
            dm_conversion,
            how='left',
            on=['m49_code','crop','year']
        )
        crop_dm_rows['dm_fraction'] = crop_dm_rows['dm_fraction'].replace(0, np.nan)
        crop_dm_rows = crop_dm_rows.dropna(subset=['dm_fraction'])
        crop_dm_rows['commodity'] = crop_dm_rows['crop'].map((maps.production_by_item or {}))
        crop_dm_rows['commodity'] = crop_dm_rows['commodity'].fillna(crop_dm_rows['crop'])
        if conv_mult:
            keys = list(zip(
                crop_dm_rows['country'].astype(str),
                crop_dm_rows['commodity'].astype(str),
                crop_dm_rows['year'].astype(int)
            ))
            mult = np.array([conv_mult.get(k, 1.0) for k in keys], dtype=float)
            mult = np.where(np.isfinite(mult), mult, 1.0)
            mult = np.clip(mult, 1e-6, None)
            crop_dm_rows['dm_fraction'] = crop_dm_rows['dm_fraction'] * mult
        crop_dm_rows['grain_need_kg'] = crop_dm_rows['crop_dm_kg'] / crop_dm_rows['dm_fraction']
        crop_dm_rows = crop_dm_rows[crop_dm_rows['commodity'].isin(universe.commodities)]
        crop_dm_rows['feed_t'] = crop_dm_rows['grain_need_kg'] / 1000.0
        # âœ… ä¿ç•™M49_Country_Codeåˆ—ï¼ˆé‡å‘½åm49_codeä¸ºæ ‡å‡†åˆ—åï¼‰
        if 'm49_code' in crop_dm_rows.columns:
            crop_dm_rows['M49_Country_Code'] = crop_dm_rows['m49_code']
        crop_feed_demand = crop_dm_rows.groupby(
            ['M49_Country_Code','country','iso3','year','commodity'],
            as_index=False
        )['feed_t'].sum()

    grass_req = stock.groupby(['country','iso3','m49_code','year'], as_index=False)['grass_dm_kg'].sum()
    logger.info(f"[S3_2 DEBUG] è‰åœ°DMéœ€æ±‚èšåˆå®Œæˆ: {len(grass_req)}è¡Œ, å¹´ä»½èŒƒå›´: {grass_req['year'].min()}-{grass_req['year'].max()}")
    
    # ğŸ” è¯Šæ–­ï¼šä»¥ç¾å›½ä¸ºä¾‹è¿½è¸ªè‰åœ°DMéœ€æ±‚
    us_grass = grass_req[grass_req['country'] == 'United States of America']
    if not us_grass.empty:
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ” [ç¾å›½æ•°æ®æµ] Step 6: è‰åœ°DMéœ€æ±‚è®¡ç®—")
        logger.info("=" * 80)
        for _, row in us_grass.iterrows():
            logger.info(f"  {row['year']}å¹´: è‰åœ°DMéœ€æ±‚ = {row['grass_dm_kg']:>15,.0f} kg")
    
    grass_req = grass_req.merge(pasture_yield, how='left', on='m49_code')
    
    # âœ… DEBUG: æ£€æŸ¥pasture_yieldåŒ¹é…æƒ…å†µ
    missing_yield = grass_req['pasture_yield_kg_per_ha'].isna().sum()
    if missing_yield > 0:
        logger.warning(f"[S3_2 WARN] âš ï¸ {missing_yield}/{len(grass_req)}è¡Œç¼ºå¤±pasture_yieldæ•°æ®ï¼")
        missing_countries = grass_req[grass_req['pasture_yield_kg_per_ha'].isna()]['country'].unique()
        logger.warning(f"[S3_2 WARN] ç¼ºå¤±yieldçš„å›½å®¶æ ·ä¾‹: {list(missing_countries)[:10]}")
    
    grass_req['grass_tdm'] = grass_req['grass_dm_kg'] / 1000.0
    grass_req['grass_area_need_ha'] = grass_req['grass_dm_kg'] / grass_req['pasture_yield_kg_per_ha'].replace(0, np.nan)
    
    # âœ… DEBUG: æ£€æŸ¥areaè®¡ç®—ç»“æœ
    area_na_count = grass_req['grass_area_need_ha'].isna().sum()
    if area_na_count > 0:
        logger.warning(f"[S3_2 WARN] âš ï¸ {area_na_count}/{len(grass_req)}è¡Œçš„grass_area_need_haä¸ºNaNï¼ˆå¯èƒ½pasture_yield=0æˆ–NaNï¼‰")
    
    # ğŸ” è¯Šæ–­ï¼šä»¥ç¾å›½ä¸ºä¾‹è¿½è¸ªè‰åœ°é¢ç§¯éœ€æ±‚
    us_grass_area = grass_req[grass_req['country'] == 'United States of America']
    if not us_grass_area.empty:
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ” [ç¾å›½æ•°æ®æµ] Step 7: è‰åœ°é¢ç§¯éœ€æ±‚è®¡ç®— (DM Ã· yield)")
        logger.info("=" * 80)
        for _, row in us_grass_area.iterrows():
            yield_val = row['pasture_yield_kg_per_ha']
            area_val = row['grass_area_need_ha']
            yield_str = f"{yield_val:,.0f}" if pd.notna(yield_val) else "NaN"
            area_str = f"{area_val:,.0f}" if pd.notna(area_val) else "âŒ NaN"
            logger.info(f"  {row['year']}å¹´: è‰åœ°å•äº§={yield_str:>10s} kg/ha | é¢ç§¯éœ€æ±‚={area_str:>15s} ha")
    
    # âœ… ä¿ç•™M49_Country_Codeåˆ—ï¼ˆé‡å‘½åm49_codeä¸ºæ ‡å‡†åˆ—åï¼‰
    grass_req['M49_Country_Code'] = grass_req['m49_code']
    grass_requirement = grass_req[['M49_Country_Code','country','iso3','year','grass_tdm','grass_area_need_ha']].copy()
    
    logger.info(f"[S3_2 DEBUG] âœ… grass_requirementç”Ÿæˆå®Œæˆ: {len(grass_requirement)}è¡Œ")
    for yr in [2020, 2080]:
        yr_data = grass_requirement[grass_requirement['year'] == yr]
        if not yr_data.empty:
            total_area = yr_data['grass_area_need_ha'].sum()
            valid_area = yr_data['grass_area_need_ha'].notna().sum()
            logger.info(f"[S3_2 DEBUG]   {yr}å¹´: {len(yr_data)}è¡Œ, æœ‰æ•ˆé¢ç§¯æ•°æ®: {valid_area}è¡Œ, æ€»é¢ç§¯: {total_area:,.0f} ha")

    species_dm_detail = stock[['country','iso3','m49_code','year','commodity','species',
                               'stock_head','kg_dm_per_head','dm_total_kg','grass_dm_kg','crop_dm_kg']].copy()

    return FeedDemandOutputs(
        crop_feed_demand=crop_feed_demand,
        grass_requirement=grass_requirement,
        species_dm_detail=species_dm_detail
    )


def _parse_m49(val: Optional[str]) -> Optional[str]:
    if val is None:
        return None
    digits = ''.join(ch for ch in str(val) if ch.isdigit())
    if not digits:
        return None
    return digits.zfill(3)


def _normalize_m49(series: pd.Series) -> pd.Series:
    return series.astype(str).apply(_parse_m49)


def _load_total_dm_per_head(xlsx_path: str, years: List[int]) -> pd.DataFrame:
    df = pd.read_excel(xlsx_path, sheet_name='total_kgDM_per_head')
    df.columns = [str(c).strip() for c in df.columns]
    df['m49_code'] = _normalize_m49(df['M49_Country_Code'])
    value_cols = [c for c in df.columns if c.startswith('Y') and c[1:].isdigit()]
    frames = []
    for col in value_cols:
        year = int(col[1:])
        if year not in years:
            continue
        tmp = df[['Species','m49_code', col]].copy()
        tmp = tmp.rename(columns={'Species':'species', col:'kg_dm_per_head'})
        tmp['year'] = year
        frames.append(tmp)
    out = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()
    if out.empty:
        return out
    out = _extend_years(out, ['species','m49_code'], 'kg_dm_per_head', years)
    return out


def _load_crop_share(xlsx_path: str, years: List[int]) -> pd.DataFrame:
    df = pd.read_excel(xlsx_path, sheet_name='kgDM_per_head_crop_shares')
    df.columns = [str(c).strip() for c in df.columns]
    df['m49_code'] = _normalize_m49(df['M49_Country_Code'])
    df['crop'] = df['Crop'].astype(str).str.strip()
    value_cols = [c for c in df.columns if c.startswith('Y') and c[1:].isdigit()]
    frames = []
    for col in value_cols:
        year = int(col[1:])
        if year not in years:
            continue
        tmp = df[['Species','m49_code','crop', col]].copy()
        tmp = tmp.rename(columns={'Species':'species', col:'share'})
        tmp['year'] = year
        frames.append(tmp)
    out = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()
    if out.empty:
        return out
    out = _extend_years(out, ['species','m49_code','crop'], 'share', years)
    return out


def _load_dm_conversion(xlsx_path: str, years: List[int]) -> pd.DataFrame:
    df = pd.read_excel(xlsx_path, sheet_name='dm_conversion_coefficients')
    df.columns = [str(c).strip() for c in df.columns]
    df['m49_code'] = _normalize_m49(df['M49_Country_Code'])
    df['crop'] = df['Crop'].astype(str).str.strip()
    value_cols = [c for c in df.columns if c.startswith('Y') and c[1:].isdigit()]
    frames = []
    for col in value_cols:
        year = int(col[1:])
        if year not in years:
            continue
        tmp = df[['m49_code','crop', col]].copy()
        tmp = tmp.rename(columns={col: 'dm_fraction'})
        tmp['year'] = year
        frames.append(tmp)
    out = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()
    if out.empty:
        return out
    out = _extend_years(out, ['m49_code','crop'], 'dm_fraction', years)
    return out


def _load_grass_ratio(xlsx_path: str) -> pd.DataFrame:
    df = pd.read_excel(xlsx_path, sheet_name='country_level_weighted')
    df.columns = [str(c).strip() for c in df.columns]
    df['m49_code'] = _normalize_m49(df['M49_Country_Code'])
    df['species'] = df['Species'].astype(str).str.strip()
    df['grass_ratio'] = pd.to_numeric(df.get('Grass'), errors='coerce')
    df['crop_ratio'] = pd.to_numeric(df.get('Crop'), errors='coerce')
    return df[['species','m49_code','grass_ratio','crop_ratio']].dropna(subset=['m49_code','species'])


def _load_pasture_yield(xlsx_path: str) -> pd.DataFrame:
    df = pd.read_excel(xlsx_path, sheet_name='pasture_DM_yield')
    df.columns = [str(c).strip() for c in df.columns]
    df['m49_code'] = _normalize_m49(df['M49_Country_Code'])
    df['pasture_yield_kg_per_ha'] = pd.to_numeric(df.get('mean_AGB_kg_ha_weighted_by_area'), errors='coerce')
    return df[['m49_code','pasture_yield_kg_per_ha']].dropna(subset=['m49_code'])


def _extend_years(df: pd.DataFrame,
                  key_cols: List[str],
                  value_col: str,
                  years: List[int]) -> pd.DataFrame:
    """
    æ‰©å±•å¹´ä»½æ•°æ®åˆ°æ‰€æœ‰è¯·æ±‚çš„å¹´ä»½
    âœ… ä¿®å¤ï¼šå½“ä»ä¼˜åŒ–å­˜æ åŠ¨æ€è®¡ç®—è‰åœ°éœ€æ±‚æ—¶ï¼Œéœ€è¦æ‰©å±•åˆ°æœªæ¥å¹´ä»½ï¼ˆ2020-2080ï¼‰
    ç­–ç•¥ï¼šå°†æœ€è¿‘çš„å†å²å¹´ä»½æ•°æ®ï¼ˆé€šå¸¸æ˜¯2020å¹´ï¼‰å‰å‘å¡«å……åˆ°æ‰€æœ‰æœªæ¥å¹´ä»½
    
    è¿™æ˜¯åˆç†çš„ï¼Œå› ä¸ºï¼š
    - DM per head (æ¯å¤´å¹²ç‰©è´¨éœ€æ±‚)ï¼šæŠ€æœ¯å‚æ•°ï¼ŒçŸ­æœŸå†…ç›¸å¯¹ç¨³å®š
    - Crop share (ä½œç‰©é¥²æ–™åˆ†é…)ï¼šé¥²æ–™é…æ–¹ï¼ŒåŸºäºå†å²æ¨¡å¼
    - Grass ratio (è‰æ–™æ¯”ä¾‹)ï¼šé¥²å…»æ–¹å¼ï¼Œå‡è®¾å»¶ç»­
    è¿™äº›å‚æ•°çš„æœªæ¥å˜åŒ–åº”è¯¥é€šè¿‡scenarioè°ƒæ•´ï¼Œè€Œä¸æ˜¯å®Œå…¨ç¼ºå¤±æ•°æ®
    """
    if df.empty:
        return df
    pivot = df.pivot_table(index=key_cols, columns='year', values=value_col, aggfunc='last')
    
    # âœ… ä¸ºæ‰€æœ‰è¯·æ±‚çš„å¹´ä»½åˆ›å»ºåˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    all_years = sorted(set(years))
    for y in all_years:
        if y not in pivot.columns:
            pivot[y] = np.nan
    
    pivot = pivot.reindex(sorted(pivot.columns), axis=1)
    pivot = pivot.ffill(axis=1)  # âœ… å‰å‘å¡«å……åˆ°æ‰€æœ‰å¹´ä»½ï¼ˆåŒ…æ‹¬æœªæ¥ï¼‰
    pivot = pivot.reset_index()
    long_df = pivot.melt(id_vars=key_cols, var_name='year', value_name=value_col)
    long_df['year'] = long_df['year'].astype(int)
    long_df = long_df[long_df['year'].isin(all_years)]  # âœ… ä¿ç•™æ‰€æœ‰è¯·æ±‚çš„å¹´ä»½
    return long_df
